ğŸŒ Kubernetes Home Lab â€“ Productionâ€‘Style Cluster & Monitoring Stack
This repository contains a fully documented, productionâ€‘inspired Kubernetes home lab. It demonstrates realâ€‘world platform engineering practices including GitOpsâ€‘style organization, observability, application deployment, storage, and cluster operations.

The goal of this project is to showcase handsâ€‘on Kubernetes expertise suitable for cloud engineering roles, including cluster design, monitoring, troubleshooting, and application lifecycle management.

ğŸ“ Repository Structure
Code
k8s-lab/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ podinfo/
â”‚   â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”‚   â”œâ”€â”€ service.yaml
â”‚   â”‚   â”œâ”€â”€ ingress.yaml
â”‚   â”‚   â”œâ”€â”€ servicemonitor.yaml
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ ...
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ kube-prometheus-stack/
â”‚   â”œâ”€â”€ grafana/
â”‚   â”œâ”€â”€ dashboards/
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ longhorn/
â”‚   â””â”€â”€ README.md
â””â”€â”€ README.md   â† (this file)
This layout mirrors GitOps conventions used in production clusters.

ğŸš€ Cluster Overview
This Kubernetes cluster is built to emulate realâ€‘world operational environments:

Multiâ€‘node cluster (control plane + workers)

Container runtime: containerd

CNI: Calico

Load balancer: MetalLB

Ingress: NGINX Ingress Controller

Storage: Longhorn distributed block storage

Monitoring: Prometheus Operator + Grafana

Applications: Podinfo (demo microservice)

The cluster is designed for iterative learning, troubleshooting, and portfolioâ€‘ready documentation.

ğŸ“¡ Monitoring Stack (Prometheus Operator)
The monitoring stack is deployed using kubeâ€‘prometheusâ€‘stack, which includes:

Prometheus Operator

Prometheus

Alertmanager

Grafana

Node Exporter

kubeâ€‘stateâ€‘metrics

This setup provides:

automatic target discovery

ServiceMonitorâ€‘based scraping

clusterâ€‘level and applicationâ€‘level metrics

productionâ€‘style dashboards

See monitoring/README.md for detailed configuration.

ğŸ“¦ Application: Podinfo
Podinfo is deployed as a demo microservice to validate:

Ingress routing

ServiceMonitor scraping

Prometheus metrics

Grafana dashboards

Applicationâ€‘level observability

Key Features
/ â€“ UI

/ping â€“ increments UI counter

/metrics â€“ Prometheus metrics endpoint

/readyz and /healthz â€“ probes

Metrics Exposed
Podinfo 6.5.x exposes:

http_requests_total â€“ total HTTP requests

http_request_duration_seconds_* â€“ latency histogram

Go runtime metrics

Process metrics

Important Note About Ping Counter
The UI â€œPingâ€ counter only increments for /ping.
Prometheus metrics count all HTTP traffic, including:

/

/metrics (scraped every 15s)

/healthz

/readyz

/api_info

/ping

This is why Prometheus counters are much higher than the UI ping counter.

ğŸ“Š PromQL Queries
Request Rate (RPS)
Code
sum(rate(http_requests_total[1m]))
Pingâ€‘Only Traffic
Code
sum(rate(http_request_duration_seconds_count{path="ping"}[1m]))
Latency (P95)
Code
histogram_quantile(
  0.95,
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le)
)
Pod CPU Usage
Code
sum(rate(container_cpu_usage_seconds_total{pod=~"podinfo.*"}[5m])) by (pod)

ğŸ“ˆ Grafana Dashboards
Dashboards included:

Cluster health

Node performance

Podinfo application dashboard

Longhorn storage dashboard

Custom panels for request rate, latency, and pod health

Dashboards are stored under:

Code
monitoring/dashboards/

ğŸ§ª Troubleshooting Notes
This repo documents real troubleshooting scenarios, including:

ServiceMonitor not scraping

Missing application metrics

kubelet vs. appâ€‘level metrics

Longhorn metrics integration

Prometheus scrape path validation

Inâ€‘cluster debugging using BusyBox

Example validation command:

Code
kubectl run tmp --rm -it --image=busybox -- sh
wget -qO- http://podinfo.apps.svc.cluster.local:80/metrics

ğŸ§­ Goals of This Project
This repository demonstrates:

Kubernetes operational maturity

GitOpsâ€‘style repo structure

Monitoring and observability expertise

Realâ€‘world troubleshooting

Productionâ€‘grade documentation

Applicationâ€‘level metrics integration

Storage and networking fundamentals

It is designed to serve as a portfolio centerpiece for cloud engineering roles.

ğŸ“Œ Next Steps
Add CI/CD (GitHub Actions or ArgoCD)

Add more microservices

Add autoscaling (HPA + metrics)

Add logging stack (Loki or EFK)

Add synthetic monitoring (Blackbox Exporter)

Add cluster architecture diagram

ğŸ How to Deploy
Code
kubectl apply -f monitoring/
kubectl apply -f storage/
kubectl apply -f apps/

ğŸ“¬ Contact / Notes
This repo is actively maintained as part of ongoing Kubernetes learning and professional development.